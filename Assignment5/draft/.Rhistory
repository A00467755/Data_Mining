by = "confidence",
decreasing = TRUE)
plot(rules_sorted[1:20],Â 
inspect(rules_sorted[1:100])
plot(rules_sorted[1:20],
method="graph",
engine="visNetwork")
library(plyr)
library(arules)
df_session = read.csv("D:/#Spring 2023/5580 - Text Mining/Assignment3/sessionDistinctMilestoneDec15 (2).csv")
df_session$id = paste(as.character(df_session$user_id) , as.POSIXct(df_session$date, format="%Y-%m-%d"))
# Transpose source
df_session= ddply(df_session,c("id"),function(dfl)paste(dfl$milestone_name, collapse=","))
# Remove id field
df_session$id = NULL
df_session$date = NULL
df_session$user_id = NULL
# Write to temp file
write.table(df_session,"D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",quote=FALSE,row.names=FALSE,col.names=FALSE)
# Read temp file
tr = read.transactions("D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",format="basket",sep=",")
# Plot Frequent items
#summary(tr)
itemFrequencyPlot(tr, topN=10)
# List the rules
rules<- apriori(tr, parameter= list(supp=0.25, conf=0.5))
inspect(sort(rules,by='lift'))
# Visualize the rules
plot(rules,
method="graph",
engine="visNetwork")
library(arulesViz)
# Visualize the rules
plot(rules,
method="graph",
engine="visNetwork")
library(plyr)
library(arules)
library(arulesViz)
df_session = read.csv("D:/#Spring 2023/5580 - Text Mining/Assignment3/sessionDistinctMilestoneDec15 (2).csv")
df_session$id = paste(as.character(df_session$user_id) , as.POSIXct(df_session$date, format="%Y-%m-%d"))
# Transpose source
df_session= ddply(df_session,c("id"),function(dfl)paste(dfl$milestone_name, collapse=","))
# Remove id field
df_session$id = NULL
df_session$date = NULL
df_session$user_id = NULL
# Write to temp file
write.table(df_session,"D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",quote=FALSE,row.names=FALSE,col.names=FALSE)
# Read temp file
tr = read.transactions("D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",format="basket",sep=",")
# Plot Frequent items
#summary(tr)
itemFrequencyPlot(tr, topN=10)
# List the rules
rules<- apriori(tr, parameter= list(supp=0.25, conf=0.5))
inspect(sort(rules,by='lift'))
# Visualize the rules
plot(rules,
method="graph",
engine="visNetwork")
# List item set
itemsets=unique(generatingItemsets(rules))
inspect(sort(itemsets,by='support'))
itemFrequencyPlot(tr, topN=10)
library(plyr)
library(arules)
library(arulesViz)
df_session = read.csv("D:/#Spring 2023/5580 - Text Mining/Assignment3/sessionDistinctMilestoneDec15 (2).csv")
df_session$id = paste(as.character(df_session$user_id) , as.POSIXct(df_session$date, format="%Y-%m-%d"))
# Transpose source
df_session= ddply(df_session,c("id"),function(dfl)paste(dfl$milestone_name, collapse=","))
# Remove id field
df_session$id = NULL
df_session$date = NULL
df_session$user_id = NULL
# Write to temp file
write.table(df_session,"D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",quote=FALSE,row.names=FALSE,col.names=FALSE)
# Read temp file
tr = read.transactions("D:/#Spring 2023/5580 - Text Mining/Assignment3/session2.csv",format="basket",sep=",")
itemFrequencyPlot(tr, topN=10)
rules<- apriori(tr, parameter= list(supp=0.25, conf=0.5))
inspect(sort(rules,by='lift'))
plot(rules,
method="graph",
engine="visNetwork")
itemFrequencyPlot(tr, topN=10)
plot(rules,
method="graph",
engine="visNetwork")
# Visualize the rules
plot(rules,
method="graph",
engine="visNetwork")
summary(tr)
inspect(sort(rules,by='lift'))
plot(rules,
method="graph",
engine="visNetwork")
itemsets=unique(generatingItemsets(rules))
inspect(sort(itemsets,by='support'))
library(tidyverse)
library(caret)
setwd("C:/")
set.seed(1)
# Read the data file which has info about top 6 products from sales219
data <- read.csv('data.csv')
#------------------------------------------------------------------
# selected product = 1st Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[1]
# Neural Network 3 hidden layer (5, 5, 5)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
library(tidyverse)
library(caret)
#setwd("C:/")
setwd("D:/#Spring 2023/5580 - Text Mining/Assignment5/draft")
set.seed(1)
# Read the data file which has info about top 6 products from sales219
data <- read.csv('data.csv')
# Get top 6 product ids in list
top_products <- data %>%
group_by(item_sk) %>%
summarize(total_quantity = sum(quantity)) %>%
select(item_sk, total_quantity) %>%
arrange(desc(total_quantity))
# Get the first product and analyze
#------------------------------------------------------------------
# selected product = 1st Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[1]
product
# Filter the data for selected product only
xy <- data %>%
filter(item_sk == product, quantity != 3) %>%  # filter product & outliner
select(-item_sk)
# Check for any missing dates in the data
is_continuous <- all(diff(xy$Date) == 1)
# Remove the data as well
xy$date <- NULL
# Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
total_rows = nrow(xy)
rows_to_reshape = total_rows - (total_rows %% 8)
reshaped_xy <-
as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
train<-reshaped_xy[trainIndex,]
test<-reshaped_xy[-trainIndex,]
# Set X and y
X <- train[,1:7]
y <- train[,8]
X_test <- test[,1:7]
y_test <- test[,8]
myCvControl <- trainControl(method = "repeatedCV",
number=10,
repeats = 5)
# Neural Network 3 hidden layer (5, 5, 5)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
plot(nnFitTime)
y_hat = predict(nnFitTime, newdata = X)
plot(y_hat)
plot(nnFitTime$finalModel, type = "performance")
plot(nnFitTime$finalModel, type = "performance")
plot(nnFitTime$finalModel)
plot(nnFitTime$finalModel)
library(tidyverse)
library(caret)
#setwd("C:/")
setwd("D:/#Spring 2023/5580 - Text Mining/Assignment5/draft")
set.seed(2)
# Read the data file which has info about top 6 products from sales219
data <- read.csv('data.csv')
# Get top 6 product ids in list
top_products <- data %>%
group_by(item_sk) %>%
summarize(total_quantity = sum(quantity)) %>%
select(item_sk, total_quantity) %>%
arrange(desc(total_quantity))
# Get the first product and analyze
#------------------------------------------------------------------
# selected product = 1st Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[1]
product
# Filter the data for selected product only
xy <- data %>%
filter(item_sk == product, quantity != 3) %>%  # filter product & outliner
select(-item_sk)
# Check for any missing dates in the data
is_continuous <- all(diff(xy$Date) == 1)
# Remove the data as well
xy$date <- NULL
# Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
total_rows = nrow(xy)
rows_to_reshape = total_rows - (total_rows %% 8)
reshaped_xy <-
as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
train<-reshaped_xy[trainIndex,]
test<-reshaped_xy[-trainIndex,]
# Set X and y
X <- train[,1:7]
y <- train[,8]
X_test <- test[,1:7]
y_test <- test[,8]
myCvControl <- trainControl(method = "repeatedCV",
number=10,
repeats = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
# Neural Network 3 hidden layer (5, 5, 5)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
plot(nnFitTime$finalModel)
plot(nnFitTime$finalModel)
summary(nnFitTime)
# MAPE Training
y_hat = predict(nnFitTime, newdata = X)
mean(100*abs(y_hat-y)/y)
# MAPE Testing
y_hat2 = predict(nnFitTime, newdata = X_test)
mean(100*abs(y_hat2-y_test)/y_test)
library(tidyverse)
library(caret)
#setwd("C:/")
setwd("D:/#Spring 2023/5580 - Text Mining/Assignment5/draft")
# Read the data file which has info about top 6 products from sales219
data <- read.csv('data.csv')
# Get top 6 product ids in list
top_products <- data %>%
group_by(item_sk) %>%
summarize(total_quantity = sum(quantity)) %>%
select(item_sk, total_quantity) %>%
arrange(desc(total_quantity))
# Get the first product and analyze
#------------------------------------------------------------------
# selected product = 1st Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[1]
product
# Filter the data for selected product only
xy <- data %>%
filter(item_sk == product, quantity != 3) %>%  # filter product & outliner
select(-item_sk)
# Check for any missing dates in the data
is_continuous <- all(diff(xy$Date) == 1)
# Remove the data as well
xy$date <- NULL
# Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
total_rows = nrow(xy)
rows_to_reshape = total_rows - (total_rows %% 8)
reshaped_xy <-
as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
train<-reshaped_xy[trainIndex,]
test<-reshaped_xy[-trainIndex,]
# Set X and y
X <- train[,1:7]
y <- train[,8]
X_test <- test[,1:7]
y_test <- test[,8]
myCvControl <- trainControl(method = "repeatedCV",
number=10,
repeats = 5)
# Neural Network 1 hidden layer (15)
grid <-  expand.grid(layer1 = 15,
layer2 = 0,
layer3 = 0)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
tuneGrid = grid,
learningrate=0.01,
preProc = c("center", "scale"),
threshold = 0.05,
trControl = myCvControl
)
nnFitTime
summary(nnFitTime)
# MAPE Training
y_hat = predict(nnFitTime, newdata = X)
mean(100*abs(y_hat-y)/y)
# MAPE Testing
y_hat2 = predict(nnFitTime, newdata = X_test)
mean(100*abs(y_hat2-y_test)/y_test)
plot(nnFitTime$finalModel)
# Neural Network 3 hidden layer (5, 5, 5)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
summary(nnFitTime)
# MAPE Training
y_hat = predict(nnFitTime, newdata = X)
mean(100*abs(y_hat-y)/y)
# MAPE Testing
y_hat2 = predict(nnFitTime, newdata = X_test)
mean(100*abs(y_hat2-y_test)/y_test)
plot(nnFitTime$finalModel)
plot(nnFitTime$finalModel)
# selected product = 3rd Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[3]
product
# Filter the data for selected product only
xy <- data %>%
filter(item_sk == product, quantity != 1) %>%  # filter product & outliner
select(-item_sk)
# Check for any missing dates in the data
is_continuous <- all(diff(xy$Date) == 1)
# Remove the data as well
xy$date <- NULL
# Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
total_rows = nrow(xy)
rows_to_reshape = total_rows - (total_rows %% 8)
reshaped_xy <-
as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
train<-reshaped_xy[trainIndex,]
test<-reshaped_xy[-trainIndex,]
# Set X and y
X <- train[,1:7]
y <- train[,8]
X_test <- test[,1:7]
y_test <- test[,8]
myCvControl <- trainControl(method = "repeatedCV",
number=10,
repeats = 5)
# Neural Network 1 hidden layer (15)
grid <-  expand.grid(layer1 = 15,
layer2 = 0,
layer3 = 0)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
tuneGrid = grid,
learningrate=0.01,
preProc = c("center", "scale"),
threshold = 0.05,
trControl = myCvControl
)
plot(nnFitTime$finalModel)
View(nnFitTime)
plot(nnFitTime$finalModel, type = "performance")
grid <-  expand.grid(layer1 = 15,
layer2 = 0,
layer3 = 0)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
tuneGrid = grid,
learningrate=0.01,
preProc = c("center", "scale"),
threshold = 0.05,
trControl = myCvControl,
linear.output = T
)
plot(nnFitTime$finalModel)
summary(nnFitTime)
nnFitTime
nnFitTime
# Neural Network 3 hidden layer (5, 5, 5)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.05,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
plot(nnFitTime$finalModel)
#------------------------------------------------------------------
# selected product = 5th Top
#11740941
#11741274
#11629829
product <- top_products$item_sk[5]
product
# Filter the data for selected product only
xy <- data %>%
filter(item_sk == product, quantity != 603) %>%  # filter product & outliner
select(-item_sk)
# Check for any missing dates in the data
is_continuous <- all(diff(xy$Date) == 1)
# Remove the data as well
xy$date <- NULL
# Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
total_rows = nrow(xy)
rows_to_reshape = total_rows - (total_rows %% 8)
reshaped_xy <-
as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
train<-reshaped_xy[trainIndex,]
test<-reshaped_xy[-trainIndex,]
# Set X and y
X <- train[,1:7]
y <- train[,8]
X_test <- test[,1:7]
y_test <- test[,8]
myCvControl <- trainControl(method = "repeatedCV",
number=10,
repeats = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
tuneGrid = grid,
learningrate=0.01,
preProc = c("center", "scale"),
threshold = 0.1,
trControl = myCvControl
)
# Neural Network 1 hidden layer (15)
grid <-  expand.grid(layer1 = 15,
layer2 = 0,
layer3 = 0)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
tuneGrid = grid,
learningrate=0.01,
preProc = c("center", "scale"),
threshold = 0.1,
trControl = myCvControl
)
plot(nnFitTime$finalModel)
grid <-  expand.grid(layer1 = 5,
layer2 = 5,
layer3 = 5)
nnFitTime <- train(V8 ~ .,
data = train,
method = "neuralnet",
algorithm="backprop",
learningrate=0.01,
tuneGrid = grid,
threshold = 0.1,
preProc = c("center", "scale", "nzv"),
trControl = myCvControl
)
plot(nnFitTime$finalModel)
plot(nnFitTime$finalModel)
