Neural Network 

27 samples
 7 predictor

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 25, 24, 24, 24, 24, 24, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  74.27502  0.6669205  64.46991

Tuning parameter 'layer1' was held constant at a value of 5
Tuning parameter 'layer2' was held constant at a value of 5

Tuning parameter 'layer3' was held constant at a value of 5
> summary(nnFitTime)
                    Length Class      Mode     
call                  7    -none-     call     
response             27    -none-     numeric  
covariate           189    -none-     numeric  
model.list            2    -none-     list     
err.fct               1    -none-     function 
act.fct               1    -none-     function 
linear.output         1    -none-     logical  
data                  8    data.frame list     
exclude               0    -none-     NULL     
net.result            1    -none-     list     
weights               1    -none-     list     
generalized.weights   1    -none-     list     
startweights          1    -none-     list     
result.matrix       109    -none-     numeric  
xNames                7    -none-     character
problemType           1    -none-     character
tuneValue             3    data.frame list     
obsLevels             1    -none-     logical  
param                 3    -none-     list     
> # MAPE Training
> y_hat = predict(nnFitTime, newdata = X)
> mean(100*abs(y_hat-y)/y)
[1] 20.25919
> # MAPE Testing
> y_hat = predict(nnFitTime, newdata = X_test)
> mean(100*abs(y_hat-y)/y)
[1] 20.25919
Warning message:
In y_hat - y :
  longer object length is not a multiple of shorter object length
> 
> 
> #------------------------------------------------------------------
> # selected product = Top 1, 3, 5
> #11740941
> #11741274
> #11629829
> 
> product <- top_products$item_sk[3]
> product
[1] 11741274
> 
> # Filter the data for selected product only
> xy <- data %>% 
+   filter(item_sk == product, quantity != 1) %>%  # filter product & outliner
+   select(-item_sk)
> 
> # Check for any missing dates in the data
> 
> is_continuous <- all(diff(xy$Date) == 1)
> 
> # Remove the data as well
> xy$date <- NULL
> 
> # Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
> 
> total_rows = nrow(xy)
> rows_to_reshape = total_rows - (total_rows %% 8)
> reshaped_xy <- 
+   as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
> 
> 
> trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
> train<-reshaped_xy[trainIndex,]
> test<-reshaped_xy[-trainIndex,]
> 
> 
> # Set X and y
> X <- train[,1:7]
> y <- train[,8]
> 
> X_test <- test[,1:7]
> y_test <- test[,8]
> 
> myCvControl <- trainControl(method = "repeatedCV",
+                             number=10,
+                             repeats = 5)
Warning message:
`repeats` has no meaning for this resampling method. 
> 
> ###########################
> 
> # Neural Network
> # Averaged Neural Network
> 
> nnFitTime <- train(V8 ~ .,
+                    data = train,
+                    method = "avNNet",
+                    preProc = c("center", "scale"),
+                    trControl = myCvControl,
+                    tuneLength = 10,
+                    linout = T,
+                    trace = F,
+                    MaxNWts = 10 * (ncol(train) + 1) + 10 + 1,
+                    maxit = 500)
There were 50 or more warnings (use warnings() to see the first 50)
> nnFitTime
Model Averaged Neural Network 

27 samples
 7 predictor

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 24, 24, 24, 25, 24, 24, ... 
Resampling results across tuning parameters:

  size  decay         RMSE      Rsquared   MAE     
   1    0.0000000000  40.86630  0.6974747  36.15745
   1    0.0001000000  39.69543  0.6938531  35.53982
   1    0.0002371374  40.82776  0.6693901  36.22641
   1    0.0005623413  41.17281  0.7059073  36.91193
   1    0.0013335214  42.77346  0.7235555  38.02579
   1    0.0031622777  42.76221  0.6843879  38.04521
   1    0.0074989421  42.52195  0.6564707  38.76006
   1    0.0177827941  43.97433  0.7061528  39.72938
   1    0.0421696503  41.54189  0.6750159  36.92135
   1    0.1000000000  41.50008  0.6385133  37.24640
   3    0.0000000000  43.23709  0.6776592  38.63840
   3    0.0001000000  43.42518  0.6866793  38.84410
   3    0.0002371374  48.69762  0.6748282  42.74539
   3    0.0005623413  47.83308  0.6276170  43.76652
   3    0.0013335214  47.90450  0.6860270  43.63726
   3    0.0031622777  48.08754  0.6059826  43.29676
   3    0.0074989421  50.31338  0.6626155  45.19664
   3    0.0177827941  52.46889  0.6350046  46.80963
   3    0.0421696503  49.23684  0.6743710  44.48913
   3    0.1000000000  46.73172  0.7076312  42.45176
   5    0.0000000000  48.40451  0.6953220  43.02464
   5    0.0001000000  50.72319  0.6639018  45.66556
   5    0.0002371374  51.41627  0.6694158  46.85031
   5    0.0005623413  52.46583  0.6751791  47.98173
   5    0.0013335214  48.20882  0.6239606  42.96197
   5    0.0031622777  49.79888  0.6753384  44.95466
   5    0.0074989421  50.59906  0.6395271  45.51756
   5    0.0177827941  50.64713  0.6627184  46.07391
   5    0.0421696503  51.68224  0.6506681  47.40334
   5    0.1000000000  49.35039  0.6590756  44.76760
   7    0.0000000000  51.16702  0.6747860  45.55316
   7    0.0001000000  54.30041  0.6317430  48.25285
   7    0.0002371374  49.72136  0.6830798  44.70603
   7    0.0005623413  53.72690  0.5797754  47.78270
   7    0.0013335214  51.70374  0.6853122  47.05471
   7    0.0031622777  51.45719  0.6311227  46.27673
   7    0.0074989421  49.79025  0.6725976  44.77141
   7    0.0177827941  49.47162  0.6409687  44.97551
   7    0.0421696503  49.26165  0.6388653  45.19642
   7    0.1000000000  49.21536  0.6956809  45.32980
   9    0.0000000000  62.63879  0.6203120  55.93724
   9    0.0001000000  54.10706  0.7207324  48.19334
   9    0.0002371374  53.90189  0.6701698  47.68036
   9    0.0005623413  51.83221  0.6649190  46.88761
   9    0.0013335214  52.29526  0.6600280  46.86621
   9    0.0031622777  52.08092  0.6719419  47.16714
   9    0.0074989421  50.61349  0.6775491  45.80026
   9    0.0177827941  49.36916  0.6398464  45.16955
   9    0.0421696503  50.39015  0.6583167  46.07675
   9    0.1000000000  50.07667  0.6301381  45.77154
  11    0.0000000000  62.94623  0.6517147  54.83121
  11    0.0001000000  57.98879  0.6852610  52.67155
  11    0.0002371374  54.81499  0.6618326  48.84199
  11    0.0005623413  52.35544  0.6401913  46.45136
  11    0.0013335214  53.25125  0.6221819  48.12854
  11    0.0031622777  51.04782  0.6528458  45.91675
  11    0.0074989421  50.97686  0.6534312  45.82340
  11    0.0177827941  50.83959  0.6654414  46.40132
  11    0.0421696503  51.10508  0.6601283  46.60172
  11    0.1000000000  49.12176  0.6763467  44.80888
  13    0.0000000000       NaN        NaN       NaN
  13    0.0001000000       NaN        NaN       NaN
  13    0.0002371374       NaN        NaN       NaN
  13    0.0005623413       NaN        NaN       NaN
  13    0.0013335214       NaN        NaN       NaN
  13    0.0031622777       NaN        NaN       NaN
  13    0.0074989421       NaN        NaN       NaN
  13    0.0177827941       NaN        NaN       NaN
  13    0.0421696503       NaN        NaN       NaN
  13    0.1000000000       NaN        NaN       NaN
  15    0.0000000000       NaN        NaN       NaN
  15    0.0001000000       NaN        NaN       NaN
  15    0.0002371374       NaN        NaN       NaN
  15    0.0005623413       NaN        NaN       NaN
  15    0.0013335214       NaN        NaN       NaN
  15    0.0031622777       NaN        NaN       NaN
  15    0.0074989421       NaN        NaN       NaN
  15    0.0177827941       NaN        NaN       NaN
  15    0.0421696503       NaN        NaN       NaN
  15    0.1000000000       NaN        NaN       NaN
  17    0.0000000000       NaN        NaN       NaN
  17    0.0001000000       NaN        NaN       NaN
  17    0.0002371374       NaN        NaN       NaN
  17    0.0005623413       NaN        NaN       NaN
  17    0.0013335214       NaN        NaN       NaN
  17    0.0031622777       NaN        NaN       NaN
  17    0.0074989421       NaN        NaN       NaN
  17    0.0177827941       NaN        NaN       NaN
  17    0.0421696503       NaN        NaN       NaN
  17    0.1000000000       NaN        NaN       NaN
  19    0.0000000000       NaN        NaN       NaN
  19    0.0001000000       NaN        NaN       NaN
  19    0.0002371374       NaN        NaN       NaN
  19    0.0005623413       NaN        NaN       NaN
  19    0.0013335214       NaN        NaN       NaN
  19    0.0031622777       NaN        NaN       NaN
  19    0.0074989421       NaN        NaN       NaN
  19    0.0177827941       NaN        NaN       NaN
  19    0.0421696503       NaN        NaN       NaN
  19    0.1000000000       NaN        NaN       NaN

Tuning parameter 'bag' was held constant at a value of FALSE
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 1, decay = 1e-04 and bag = FALSE.
> summary(nnFitTime)
            Length Class      Mode     
model       5      -none-     list     
repeats     1      -none-     numeric  
bag         1      -none-     logical  
seeds       5      -none-     numeric  
names       7      -none-     character
terms       3      terms      call     
coefnames   7      -none-     character
xlevels     0      -none-     list     
xNames      7      -none-     character
problemType 1      -none-     character
tuneValue   3      data.frame list     
obsLevels   1      -none-     logical  
param       4      -none-     list     
> # MAPE Training
> y_hat = predict(nnFitTime, newdata = X)
> mean(100*abs(y_hat-y)/y)
[1] 27.33673
> # MAPE Testing
> y_hat = predict(nnFitTime, newdata = X_test)
> mean(100*abs(y_hat-y)/y)
[1] 35.18032
Warning message:
In y_hat - y :
  longer object length is not a multiple of shorter object length
> 
> # Neural Network 1 hidden layer (15)
> grid <-  expand.grid(layer1 = 15,
+                      layer2 = 0,
+                      layer3 = 0)
> 
> nnFitTime <- train(V8 ~ .,
+                    data = train,
+                    method = "neuralnet", 
+                    algorithm="backprop",
+                    tuneGrid = grid,
+                    learningrate=0.01,
+                    preProc = c("center", "scale"),
+                    threshold = 0.05,
+                    trControl = myCvControl
+ )
There were 50 or more warnings (use warnings() to see the first 50)
> 
> nnFitTime
Neural Network 

27 samples
 7 predictor

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 24, 24, 24, 24, 25, 25, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  57.32711  0.5914891  49.06199

Tuning parameter 'layer1' was held constant at a value of 15
Tuning parameter 'layer2' was held constant at a value of 0

Tuning parameter 'layer3' was held constant at a value of 0
> summary(nnFitTime)
                    Length Class      Mode     
call                  7    -none-     call     
response             27    -none-     numeric  
covariate           189    -none-     numeric  
model.list            2    -none-     list     
err.fct               1    -none-     function 
act.fct               1    -none-     function 
linear.output         1    -none-     logical  
data                  8    data.frame list     
exclude               0    -none-     NULL     
net.result            1    -none-     list     
weights               1    -none-     list     
generalized.weights   1    -none-     list     
startweights          1    -none-     list     
result.matrix       139    -none-     numeric  
xNames                7    -none-     character
problemType           1    -none-     character
tuneValue             3    data.frame list     
obsLevels             1    -none-     logical  
param                 3    -none-     list     
> # MAPE Training
> y_hat = predict(nnFitTime, newdata = X)
> mean(100*abs(y_hat-y)/y)
[1] 5.437301
> # MAPE Testing
> y_hat = predict(nnFitTime, newdata = X_test)
> mean(100*abs(y_hat-y)/y)
[1] 57.90274
Warning message:
In y_hat - y :
  longer object length is not a multiple of shorter object length
> 
> # Neural Network 3 hidden layer (5, 5, 5)
> grid <-  expand.grid(layer1 = 5,
+                      layer2 = 5,
+                      layer3 = 5)
> 
> 
> nnFitTime <- train(V8 ~ .,
+                    data = train,
+                    method = "neuralnet", 
+                    algorithm="backprop",
+                    learningrate=0.01,
+                    tuneGrid = grid,
+                    threshold = 0.05,
+                    preProc = c("center", "scale", "nzv"),
+                    trControl = myCvControl
+ )
> 
> nnFitTime
Neural Network 

27 samples
 7 predictor

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 24, 24, 24, 25, 25, 24, ... 
Resampling results:

  RMSE      Rsquared   MAE     
  36.55827  0.6482728  32.36452

Tuning parameter 'layer1' was held constant at a value of 5
Tuning parameter 'layer2' was held constant at a value of 5

Tuning parameter 'layer3' was held constant at a value of 5
> summary(nnFitTime)
                    Length Class      Mode     
call                  7    -none-     call     
response             27    -none-     numeric  
covariate           189    -none-     numeric  
model.list            2    -none-     list     
err.fct               1    -none-     function 
act.fct               1    -none-     function 
linear.output         1    -none-     logical  
data                  8    data.frame list     
exclude               0    -none-     NULL     
net.result            1    -none-     list     
weights               1    -none-     list     
generalized.weights   1    -none-     list     
startweights          1    -none-     list     
result.matrix       109    -none-     numeric  
xNames                7    -none-     character
problemType           1    -none-     character
tuneValue             3    data.frame list     
obsLevels             1    -none-     logical  
param                 3    -none-     list     
> # MAPE Training
> y_hat = predict(nnFitTime, newdata = X)
> mean(100*abs(y_hat-y)/y)
[1] 31.52741
> # MAPE Testing
> y_hat = predict(nnFitTime, newdata = X_test)
> mean(100*abs(y_hat-y)/y)
[1] 31.5274
Warning message:
In y_hat - y :
  longer object length is not a multiple of shorter object length
> product <- top_products$item_sk[5]
> product
[1] 11629829
> 
> # Filter the data for selected product only
> xy <- data %>% 
+   filter(item_sk == product, quantity != 603) %>%  # filter product & outliner
+   select(-item_sk)
> 
> # Check for any missing dates in the data
> 
> is_continuous <- all(diff(xy$Date) == 1)
> 
> # Remove the data as well
> xy$date <- NULL
> 
> # Reshape the dataframe to have 7 independent and 1 dependent (8 in total cols)
> 
> total_rows = nrow(xy)
> rows_to_reshape = total_rows - (total_rows %% 8)
> reshaped_xy <- 
+   as.data.frame(matrix(xy[1:rows_to_reshape, 1], ncol = 8, byrow = TRUE))
> 
> 
> trainIndex<-createDataPartition(reshaped_xy$V8, p=0.8, list=FALSE)
> train<-reshaped_xy[trainIndex,]
> test<-reshaped_xy[-trainIndex,]
> 
> 
> # Set X and y
> X <- train[,1:7]
> y <- train[,8]
> 
> X_test <- test[,1:7]
> y_test <- test[,8]
> 
> myCvControl <- trainControl(method = "repeatedCV",
+                             number=10,
+                             repeats = 5)
Warning message:
`repeats` has no meaning for this resampling method. 
> 
> ###########################
> 
> # Neural Network
> # Averaged Neural Network
> 
> nnFitTime <- train(V8 ~ .,
+                    data = train,
+                    method = "avNNet",
+                    preProc = c("center", "scale"),
+                    trControl = myCvControl,
+                    tuneLength = 10,
+                    linout = T,
+                    trace = F,
+                    MaxNWts = 10 * (ncol(train) + 1) + 10 + 1,
+                    maxit = 500)
There were 50 or more warnings (use warnings() to see the first 50)
> nnFitTime
Model Averaged Neural Network 

27 samples
 7 predictor

Pre-processing: centered (7), scaled (7) 
Resampling: Cross-Validated (10 fold, repeated 5 times) 
Summary of sample sizes: 25, 24, 25, 24, 24, 25, ... 
Resampling results across tuning parameters:

  size  decay         RMSE       Rsquared   MAE      
   1    0.0000000000   67.61742  0.5419107   56.85278
   1    0.0001000000   70.03740  0.5848300   57.99365
   1    0.0002371374   68.45200  0.6044821   55.82924
   1    0.0005623413   69.52157  0.6014903   57.79045
   1    0.0013335214   72.61045  0.5818957   61.14041
   1    0.0031622777   79.08895  0.6235959   65.41847
   1    0.0074989421   78.42281  0.6389407   65.01560
   1    0.0177827941   78.07953  0.6237280   63.35582
   1    0.0421696503   78.81225  0.6035335   64.75850
   1    0.1000000000   80.82986  0.5890426   66.84547
   3    0.0000000000   78.69451  0.5664592   63.64302
   3    0.0001000000   83.09838  0.6159756   68.31346
   3    0.0002371374   92.61100  0.6318446   77.28006
   3    0.0005623413   98.12514  0.5768399   81.68002
   3    0.0013335214   99.35576  0.6440028   82.65788
   3    0.0031622777  100.35634  0.5971526   83.22458
   3    0.0074989421   95.21571  0.6838853   78.48482
   3    0.0177827941  108.15893  0.6439039   91.58653
   3    0.0421696503  104.64550  0.6704396   88.04686
   3    0.1000000000   99.41889  0.5708724   82.68653
   5    0.0000000000   93.29443  0.6106998   78.03650
   5    0.0001000000  102.00961  0.6561891   86.19905
   5    0.0002371374   95.33648  0.6329965   78.44000
   5    0.0005623413  105.72542  0.6175659   89.12801
   5    0.0013335214  106.15373  0.6126694   90.68600
   5    0.0031622777  104.37207  0.6600459   86.45576
   5    0.0074989421  104.59254  0.6328514   87.35904
   5    0.0177827941  103.84614  0.6357639   87.19503
   5    0.0421696503  102.55141  0.6384458   85.79621
   5    0.1000000000  110.39689  0.5968023   92.17050
   7    0.0000000000  108.04330  0.6184951   91.76137
   7    0.0001000000  101.87873  0.6061876   85.91805
   7    0.0002371374  107.78126  0.5766009   90.37711
   7    0.0005623413  110.88171  0.6350979   91.82222
   7    0.0013335214  110.55416  0.5962802   93.65676
   7    0.0031622777  108.46646  0.6005039   90.76052
   7    0.0074989421  110.97305  0.6007940   92.78286
   7    0.0177827941  103.05596  0.5771293   86.44246
   7    0.0421696503  106.02740  0.6480753   88.15235
   7    0.1000000000  104.40279  0.6299897   86.78981
   9    0.0000000000  106.14233  0.6878821   89.38373
   9    0.0001000000  104.78901  0.6136726   86.58549
   9    0.0002371374  106.97587  0.6105348   88.24119
   9    0.0005623413  107.04078  0.5814187   88.93777
   9    0.0013335214  108.17329  0.6641299   91.19750
   9    0.0031622777  107.33001  0.6245201   90.17972
   9    0.0074989421  107.76562  0.5775720   90.26594
   9    0.0177827941  108.41243  0.6135083   91.09988
   9    0.0421696503  107.96445  0.6270345   91.04619
   9    0.1000000000  108.23401  0.5960988   89.56491
  11    0.0000000000  118.80959  0.6551441  102.48015
  11    0.0001000000  105.83076  0.6622690   90.16589
  11    0.0002371374  111.13832  0.6237639   93.12260
  11    0.0005623413  108.99856  0.6004969   92.54712
  11    0.0013335214  106.52216  0.6537553   89.52991
  11    0.0031622777  109.84092  0.5913561   91.87461
  11    0.0074989421  110.51925  0.6080421   93.10808
  11    0.0177827941  105.90409  0.5951945   88.56435
  11    0.0421696503  107.48951  0.5618519   89.30053
  11    0.1000000000  107.26394  0.5715754   89.55944
  13    0.0000000000        NaN        NaN        NaN
  13    0.0001000000        NaN        NaN        NaN
  13    0.0002371374        NaN        NaN        NaN
  13    0.0005623413        NaN        NaN        NaN
  13    0.0013335214        NaN        NaN        NaN
  13    0.0031622777        NaN        NaN        NaN
  13    0.0074989421        NaN        NaN        NaN
  13    0.0177827941        NaN        NaN        NaN
  13    0.0421696503        NaN        NaN        NaN
  13    0.1000000000        NaN        NaN        NaN
  15    0.0000000000        NaN        NaN        NaN
  15    0.0001000000        NaN        NaN        NaN
  15    0.0002371374        NaN        NaN        NaN
  15    0.0005623413        NaN        NaN        NaN
  15    0.0013335214        NaN        NaN        NaN
  15    0.0031622777        NaN        NaN        NaN
  15    0.0074989421        NaN        NaN        NaN
  15    0.0177827941        NaN        NaN        NaN
  15    0.0421696503        NaN        NaN        NaN
  15    0.1000000000        NaN        NaN        NaN
  17    0.0000000000        NaN        NaN        NaN
  17    0.0001000000        NaN        NaN        NaN
  17    0.0002371374        NaN        NaN        NaN
  17    0.0005623413        NaN        NaN        NaN
  17    0.0013335214        NaN        NaN        NaN
  17    0.0031622777        NaN        NaN        NaN
  17    0.0074989421        NaN        NaN        NaN
  17    0.0177827941        NaN        NaN        NaN
  17    0.0421696503        NaN        NaN        NaN
  17    0.1000000000        NaN        NaN        NaN
  19    0.0000000000        NaN        NaN        NaN
  19    0.0001000000        NaN        NaN        NaN
  19    0.0002371374        NaN        NaN        NaN
  19    0.0005623413        NaN        NaN        NaN
  19    0.0013335214        NaN        NaN        NaN
  19    0.0031622777        NaN        NaN        NaN
  19    0.0074989421        NaN        NaN        NaN
  19    0.0177827941        NaN        NaN        NaN
  19    0.0421696503        NaN        NaN        NaN
  19    0.1000000000        NaN        NaN        NaN

Tuning parameter 'bag' was held constant at a value of FALSE
RMSE was used to select the optimal model using the smallest value.
The final values used for the model were size = 1, decay = 0 and bag = FALSE.
> summary(nnFitTime)
            Length Class      Mode     
model       5      -none-     list     
repeats     1      -none-     numeric  
bag         1      -none-     logical  
seeds       5      -none-     numeric  
names       7      -none-     character
terms       3      terms      call     
coefnames   7      -none-     character
xlevels     0      -none-     list     
xNames      7      -none-     character
problemType 1      -none-     character
tuneValue   3      data.frame list     
obsLevels   1      -none-     logical  
param       4      -none-     list     
> # MAPE Training
> y_hat = predict(nnFitTime, newdata = X)
> mean(100*abs(y_hat-y)/y)
[1] 69.60604
> # MAPE Testing
> y_hat = predict(nnFitTime, newdata = X_test)
> mean(100*abs(y_hat-y)/y)
[1] 102.5649
Warning message:
In y_hat - y :
  longer object length is not a multiple of shorter object length
